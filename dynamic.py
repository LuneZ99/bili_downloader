#!/usr/bin/env python3
"""
BilibiliåŠ¨æ€çˆ¬å–å™¨

æä¾›ç”¨æˆ·åŠ¨æ€å’Œè¯„è®ºçš„å®Œæ•´çˆ¬å–åŠŸèƒ½ï¼š
- è·å–ç”¨æˆ·æ‰€æœ‰åŠ¨æ€
- è·å–åŠ¨æ€è¯„è®ºå’Œæ¥¼ä¸­æ¥¼
- æ”¯æŒå¹¶å‘è·å–
- æ•°æ®ä¿å­˜ä¸ºJSONæ ¼å¼
"""

import asyncio
import json
import os
import traceback
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

from bilibili_api import user, comment, dynamic, Credential
from bilibili_api.comment import CommentResourceType
from bilibili_api.dynamic import Dynamic

from utils import get_logger, api_retry_decorator


class DynamicsCrawler:
    """Bç«™ç”¨æˆ·åŠ¨æ€çˆ¬å–å™¨"""
    
    def __init__(self, credential: Optional[Credential] = None, max_concurrent: int = 1, 
                 max_comments_per_dynamic: int = -1, base_wait_time: float = 0.1, 
                 full_sub_comments: bool = False):
        """
        åˆå§‹åŒ–åŠ¨æ€çˆ¬å–å™¨
        
        Args:
            credential: Bç«™ç™»å½•å‡­æ®
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            max_comments_per_dynamic: æ¯ä¸ªåŠ¨æ€æœ€å¤§è¯„è®ºæ•°é™åˆ¶ (-1 è¡¨ç¤ºæ— é™åˆ¶)
            base_wait_time: è¯·æ±‚ä¹‹é—´çš„åŸºæœ¬ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤0.1ç§’ï¼‰
            full_sub_comments: æ˜¯å¦è·å–å®Œæ•´æ¥¼ä¸­æ¥¼è¯„è®º (False=ä»…ä½¿ç”¨å†…åµŒæ¥¼ä¸­æ¥¼, True=å•ç‹¬è·å–å®Œæ•´æ¥¼ä¸­æ¥¼)
        """
        self.credential = credential or Credential()
        self.max_concurrent = max_concurrent
        self.max_comments_per_dynamic = max_comments_per_dynamic
        self.full_sub_comments = full_sub_comments
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.base_wait_time = base_wait_time
        self.current_wait_time = base_wait_time
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—é…ç½®
        self.logger = get_logger('DynamicsCrawler')
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_dynamics': 0,
            'processed_dynamics': 0,
            'total_comments': 0,
            'failed_dynamics': 0,
            'start_time': None
        }
    
    @api_retry_decorator()
    async def get_user_info(self, uid: int) -> Dict:
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        try:
            user_obj = user.User(uid, credential=self.credential)
            info = await user_obj.get_user_info()
            return info
        except Exception as e:
            self.logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    @api_retry_decorator()
    async def _get_dynamics_page(self, user_obj: user.User, offset: str) -> Dict:
        """è·å–ä¸€é¡µåŠ¨æ€"""
        return await user_obj.get_dynamics_new(offset=offset)

    async def get_user_all_dynamics(self, uid: int, start_page: int = 1, max_pages: Optional[int] = None) -> List[Dict]:
        """
        è·å–ç”¨æˆ·æ‰€æœ‰åŠ¨æ€
        
        Args:
            uid: ç”¨æˆ·ID
            start_page: èµ·å§‹é¡µç 
            max_pages: æœ€å¤§çˆ¬å–é¡µæ•°

        Returns:
            List[Dict]: åŠ¨æ€ä¿¡æ¯åˆ—è¡¨
        """
        user_obj = user.User(uid, credential=self.credential)
        all_dynamics = []
        offset = ""
        page = 1
        pages_crawled = 0
        
        self.logger.info(f"å¼€å§‹è·å–ç”¨æˆ· {uid} çš„åŠ¨æ€åˆ—è¡¨...")
        
        while True:
            if max_pages is not None and pages_crawled >= max_pages:
                self.logger.info(f"å·²è¾¾åˆ°æœ€å¤§çˆ¬å–é¡µæ•°é™åˆ¶ ({max_pages}é¡µ)ï¼Œåœæ­¢è·å–ã€‚")
                break

            try:
                dynamics_data = await self._get_dynamics_page(user_obj, offset)
                
                if not dynamics_data or not dynamics_data.get('items'):
                    break
                
                if page >= start_page:
                    dynamics_list = dynamics_data['items']
                    all_dynamics.extend(dynamics_list)
                    pages_crawled += 1
                    self.logger.info(f"è·å–ç¬¬ {page} é¡µï¼Œ{len(dynamics_list)} æ¡åŠ¨æ€ï¼Œç´¯è®¡ {len(all_dynamics)} æ¡ (å·²çˆ¬å– {pages_crawled} é¡µ)")
                else:
                    self.logger.info(f"è·³è¿‡ç¬¬ {page} é¡µ (èµ·å§‹é¡µ: {start_page})")

                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                if not dynamics_data.get('offset') or len(dynamics_data['items']) == 0:
                    break
                
                offset = dynamics_data['offset']
                page += 1
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(0.1)
                
            except Exception as e:
                self.logger.error(f"è·å–ç¬¬ {page} é¡µåŠ¨æ€åˆ—è¡¨å¤±è´¥: {e}")
                break
        
        self.logger.info(f"å…±è·å–åˆ° {len(all_dynamics)} æ¡åŠ¨æ€")
        self.stats['total_dynamics'] = len(all_dynamics)
        return all_dynamics
    
    @api_retry_decorator()
    async def _get_comments_page(self, oid: int, type_: CommentResourceType, offset: str) -> Dict:
        """è·å–ä¸€é¡µæ ¹è¯„è®º"""
        return await comment.get_comments_lazy(
            oid=oid,
            type_=type_,
            offset=offset,
            credential=self.credential
        )

    async def get_dynamic_comments(self, dynamic_obj: Dynamic, dynamic_type: CommentResourceType) -> Dict:
        """
        è·å–å•ä¸ªåŠ¨æ€çš„æ‰€æœ‰è¯„è®ºå’Œæ¥¼ä¸­æ¥¼
        
        Args:
            dynamic_obj: åŠ¨æ€å¯¹è±¡
            dynamic_type: è¯„è®ºèµ„æºç±»å‹
            
        Returns:
            Dict: åŒ…å«æ‰€æœ‰è¯„è®ºæ•°æ®çš„å­—å…¸
        """
        try:
            # è·å–åŠ¨æ€çš„ridä½œä¸ºè¯„è®ºåŒºoid
            rid = await dynamic_obj.get_rid()
            dynamic_id = dynamic_obj.get_dynamic_id()
            
            comments_data = {
                'root_comments': [],
                'sub_comments': {},
                'total_count': 0
            }
            
            # è·å–æ ¹è¯„è®º
            offset = ""
            comment_count = 0
            page_count = 0
            sub_comments_to_process = []
            
            self.logger.info(f"åŠ¨æ€ {dynamic_id}: å¼€å§‹è·å–æ ¹è¯„è®º...")
            
            while True:
                comments_resp = await self._get_comments_page(rid, dynamic_type, offset)

                if not comments_resp or not comments_resp.get('replies'):
                    break
                
                page_count += 1
                root_comments = comments_resp['replies']
                
                self.logger.info(f"åŠ¨æ€ {dynamic_id}: è·å–ç¬¬ {page_count} é¡µæ ¹è¯„è®ºï¼Œ{len(root_comments)} æ¡")
                
                for root_comment in root_comments:
                    comment_count += 1
                    if self.max_comments_per_dynamic != -1 and comment_count > self.max_comments_per_dynamic:
                        self.logger.warning(f"åŠ¨æ€ {dynamic_id} è¯„è®ºæ•°è¶…è¿‡é™åˆ¶ {self.max_comments_per_dynamic}")
                        break
                    
                    # æ ¹æ®ç­–ç•¥å¤„ç†æ¥¼ä¸­æ¥¼
                    if self.full_sub_comments:
                        # æ–¹æ¡ˆB: æ¸…ç©ºå†…åµŒæ¥¼ä¸­æ¥¼ï¼Œå•ç‹¬è·å–å®Œæ•´æ¥¼ä¸­æ¥¼
                        if root_comment.get('rcount', 0) > 0:
                            sub_comments_to_process.append({
                                'rpid': root_comment['rpid'],
                                'rcount': root_comment['rcount']
                            })
                        # æ¸…ç©ºå†…åµŒçš„repliesé¿å…é‡å¤
                        root_comment['replies'] = []
                    else:
                        # æ–¹æ¡ˆA: ä¿ç•™å†…åµŒæ¥¼ä¸­æ¥¼ï¼Œä¸å•ç‹¬è·å–
                        pass  # ä¿æŒåŸæœ‰çš„replieså­—æ®µ
                    
                    comments_data['root_comments'].append(root_comment)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ - ä½¿ç”¨æ­£ç¡®çš„APIå­—æ®µè·¯å¾„
                cursor = comments_resp.get('cursor', {})
                pagination_reply = cursor.get('pagination_reply', {})
                next_offset = pagination_reply.get('next_offset', '')
                
                if not next_offset:
                    self.logger.info(f"åŠ¨æ€ {dynamic_id}: æ²¡æœ‰æ›´å¤šé¡µé¢")
                    break
                
                offset = next_offset
                await asyncio.sleep(self.base_wait_time)
                
                if self.max_comments_per_dynamic != -1 and comment_count > self.max_comments_per_dynamic:
                    break

            # ç»Ÿè®¡æ¥¼ä¸­æ¥¼ä¿¡æ¯
            total_sub_comments_expected = sum(item['rcount'] for item in sub_comments_to_process)
            
            if sub_comments_to_process and self.full_sub_comments:
                # æ–¹æ¡ˆB: å•ç‹¬è·å–å®Œæ•´æ¥¼ä¸­æ¥¼
                self.logger.info(f"åŠ¨æ€ {dynamic_id}: æ ¹è¯„è®ºè·å–å®Œæˆï¼Œå…± {comment_count} æ¡æ ¹è¯„è®ºï¼Œ"
                               f"å‘ç° {len(sub_comments_to_process)} ä¸ªæ¥¼ä¸­æ¥¼ï¼Œé¢„è®¡ {total_sub_comments_expected} æ¡å­è¯„è®º")
                
                # è·å–æ¥¼ä¸­æ¥¼è¯„è®º
                processed_sub_count = 0
                for i, sub_info in enumerate(sub_comments_to_process, 1):
                    rpid = sub_info['rpid']
                    expected_count = sub_info['rcount']
                    
                    self.logger.info(f"åŠ¨æ€ {dynamic_id}: è·å–æ¥¼ä¸­æ¥¼ {i}/{len(sub_comments_to_process)} "
                                   f"(rpid: {rpid}, é¢„è®¡: {expected_count} æ¡)")
                    
                    sub_comments = await self.get_sub_comments(rid, dynamic_type, rpid)
                    if sub_comments:
                        comments_data['sub_comments'][str(rpid)] = sub_comments
                        processed_sub_count += len(sub_comments)
                        
                        self.logger.info(f"åŠ¨æ€ {dynamic_id}: æ¥¼ä¸­æ¥¼ {i}/{len(sub_comments_to_process)} å®Œæˆï¼Œ"
                                       f"å®é™…è·å– {len(sub_comments)} æ¡ï¼Œç´¯è®¡å­è¯„è®º: {processed_sub_count}")
                
                self.logger.info(f"åŠ¨æ€ {dynamic_id}: æ¥¼ä¸­æ¥¼è·å–å®Œæˆï¼Œå®é™…è·å– {processed_sub_count} æ¡å­è¯„è®º")
            else:
                # æ–¹æ¡ˆA: ä½¿ç”¨å†…åµŒæ¥¼ä¸­æ¥¼æˆ–æ— æ¥¼ä¸­æ¥¼
                if self.full_sub_comments:
                    self.logger.info(f"åŠ¨æ€ {dynamic_id}: æ ¹è¯„è®ºè·å–å®Œæˆï¼Œå…± {comment_count} æ¡ï¼Œæ— æ¥¼ä¸­æ¥¼")
                else:
                    self.logger.info(f"åŠ¨æ€ {dynamic_id}: æ ¹è¯„è®ºè·å–å®Œæˆï¼Œå…± {comment_count} æ¡ï¼Œä½¿ç”¨å†…åµŒæ¥¼ä¸­æ¥¼")

            comments_data['total_count'] = comment_count
            self.stats['total_comments'] += comment_count
            
            return comments_data
            
        except Exception as e:
            self.logger.error(f"è·å–åŠ¨æ€ {dynamic_obj.get_dynamic_id()} è¯„è®ºå¤±è´¥: {e}")
            return {'root_comments': [], 'sub_comments': {}, 'total_count': 0}
    
    @api_retry_decorator()
    async def _get_sub_comments_page(self, comment_obj: comment.Comment, page: int) -> Dict:
        """è·å–ä¸€é¡µæ¥¼ä¸­æ¥¼è¯„è®º"""
        return await comment_obj.get_sub_comments(page_index=page, page_size=20)

    async def get_sub_comments(self, oid: int, type_: CommentResourceType, root_rpid: int) -> List[Dict]:
        """
        è·å–æ¥¼ä¸­æ¥¼è¯„è®º
        
        Args:
            oid: èµ„æºID
            type_: è¯„è®ºèµ„æºç±»å‹
            root_rpid: æ ¹è¯„è®ºID
            
        Returns:
            List[Dict]: å­è¯„è®ºåˆ—è¡¨
        """
        try:
            comment_obj = comment.Comment(oid, type_, root_rpid, credential=self.credential)
            
            sub_comments = []
            page = 1
            
            while True:
                self.logger.debug(f"è·å–æ¥¼ä¸­æ¥¼ {root_rpid} ç¬¬ {page} é¡µ...")
                sub_resp = await self._get_sub_comments_page(comment_obj, page)

                if not sub_resp or not sub_resp.get('replies'):
                    break
                
                page_comments = sub_resp['replies']
                sub_comments.extend(page_comments)
                
                if page == 1:
                    self.logger.debug(f"æ¥¼ä¸­æ¥¼ {root_rpid}: ç¬¬ {page} é¡µè·å– {len(page_comments)} æ¡")
                elif page % 5 == 0 or len(page_comments) < 20:  # æ¯5é¡µæˆ–æœ€åä¸€é¡µæ‰“å°è¿›åº¦
                    self.logger.debug(f"æ¥¼ä¸­æ¥¼ {root_rpid}: ç¬¬ {page} é¡µè·å– {len(page_comments)} æ¡ï¼Œç´¯è®¡ {len(sub_comments)} æ¡")
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ
                if len(page_comments) < 20:
                    break
                
                page += 1
                await asyncio.sleep(self.base_wait_time)
            
            if page > 1:
                self.logger.debug(f"æ¥¼ä¸­æ¥¼ {root_rpid} è·å–å®Œæˆ: å…± {page} é¡µï¼Œ{len(sub_comments)} æ¡å­è¯„è®º")
            
            return sub_comments
            
        except Exception as e:
            self.logger.error(f"è·å–æ¥¼ä¸­æ¥¼è¯„è®ºå¤±è´¥ (rpid: {root_rpid}): {e}")
            return []
    
    def determine_comment_type(self, dynamic_info: Dict) -> CommentResourceType:
        """
        æ ¹æ®åŠ¨æ€ä¿¡æ¯ç¡®å®šè¯„è®ºèµ„æºç±»å‹
        
        Args:
            dynamic_info: åŠ¨æ€ä¿¡æ¯
            
        Returns:
            CommentResourceType: è¯„è®ºèµ„æºç±»å‹
        """
        # æ ¹æ®åŠ¨æ€ç±»å‹ç¡®å®šè¯„è®ºåŒºç±»å‹
        dynamic_type = dynamic_info.get('type')
        
        if dynamic_type == 'DYNAMIC_TYPE_AV':  # è§†é¢‘åŠ¨æ€
            return CommentResourceType.VIDEO
        elif dynamic_type == 'DYNAMIC_TYPE_DRAW':  # å›¾æ–‡åŠ¨æ€
            return CommentResourceType.DYNAMIC_DRAW
        elif dynamic_type == 'DYNAMIC_TYPE_ARTICLE':  # æ–‡ç« åŠ¨æ€
            return CommentResourceType.ARTICLE
        elif dynamic_type == 'DYNAMIC_TYPE_WORD':  # çº¯æ–‡æœ¬åŠ¨æ€
            return CommentResourceType.DYNAMIC
        else:
            # é»˜è®¤ä½¿ç”¨åŠ¨æ€è¯„è®ºç±»å‹
            return CommentResourceType.DYNAMIC
    
    async def save_dynamic_data(self, dynamic_info: Dict, comments_data: Dict, save_dir: Path):
        """
        ä¿å­˜åŠ¨æ€æ•°æ®åˆ°JSONæ–‡ä»¶
        
        Args:
            dynamic_info: åŠ¨æ€ä¿¡æ¯
            comments_data: è¯„è®ºæ•°æ®
            save_dir: ä¿å­˜ç›®å½•
        """
        try:
            dynamic_id = dynamic_info['id_str']
            
            # æ„å»ºå®Œæ•´çš„æ•°æ®ç»“æ„
            full_data = {
                'dynamic_info': dynamic_info,
                'comments': comments_data,
                'metadata': {
                    'crawl_time': datetime.now().isoformat(),
                    'total_comments': comments_data['total_count'],
                    'dynamic_type': dynamic_info.get('type', 'UNKNOWN'),
                    'dynamic_id': dynamic_id
                }
            }
            
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            filename = f"dynamic_{dynamic_id}.json"
            filepath = save_dir / filename
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(full_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"ä¿å­˜åŠ¨æ€æ•°æ®: {filename} ({comments_data['total_count']} æ¡è¯„è®º)")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜åŠ¨æ€æ•°æ®å¤±è´¥: {e}")
    
    async def process_single_dynamic(self, dynamic_info: Dict, save_dir: Path, 
                                   include_comments: bool = True) -> bool:
        """
        å¤„ç†å•ä¸ªåŠ¨æ€ï¼ˆåŒ…å«è¯„è®ºè·å–å’Œä¿å­˜ï¼‰
        
        Args:
            dynamic_info: åŠ¨æ€ä¿¡æ¯
            save_dir: ä¿å­˜ç›®å½•
            include_comments: æ˜¯å¦åŒ…å«è¯„è®º
            
        Returns:
            bool: å¤„ç†æ˜¯å¦æˆåŠŸ
        """
        if not self.semaphore:
            return await self._process_dynamic_impl(dynamic_info, save_dir, include_comments)
        
        async with self.semaphore:
            return await self._process_dynamic_impl(dynamic_info, save_dir, include_comments)
    
    async def _process_dynamic_impl(self, dynamic_info: Dict, save_dir: Path, 
                                  include_comments: bool) -> bool:
        """å¤„ç†å•ä¸ªåŠ¨æ€çš„å…·ä½“å®ç°"""
        dynamic_id = dynamic_info['id_str']
        start_time = datetime.now()
        
        self.logger.info(f"å¼€å§‹å¤„ç†åŠ¨æ€: {dynamic_id}")
        try:
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            filename = f"dynamic_{dynamic_id}.json"
            filepath = save_dir / filename
            
            if filepath.exists():
                self.logger.info(f"è·³è¿‡å·²å­˜åœ¨çš„åŠ¨æ€: {filename}")
                return True
            
            comments_data = {'root_comments': [], 'sub_comments': {}, 'total_count': 0}
            
            if include_comments:
                self.logger.info(f"æ­£åœ¨è·å–åŠ¨æ€ {dynamic_id} çš„è¯„è®º...")
                # åˆ›å»ºåŠ¨æ€å¯¹è±¡
                dynamic_obj = Dynamic(int(dynamic_id), credential=self.credential)
                
                # ç¡®å®šè¯„è®ºç±»å‹
                comment_type = self.determine_comment_type(dynamic_info)
                
                # è·å–è¯„è®º
                comments_data = await self.get_dynamic_comments(dynamic_obj, comment_type)
                
                # è®¡ç®—å¤„ç†æ—¶é—´
                processing_time = datetime.now() - start_time
                
                self.logger.info(f"åŠ¨æ€ {dynamic_id} è¯„è®ºè·å–å®Œæˆï¼Œå…± {comments_data['total_count']} æ¡è¯„è®ºï¼Œ"
                               f"è€—æ—¶ {processing_time.total_seconds():.1f}ç§’")
            
            # ä¿å­˜æ•°æ®
            await self.save_dynamic_data(dynamic_info, comments_data, save_dir)
            
            # æ€»å¤„ç†æ—¶é—´
            total_time = datetime.now() - start_time
            self.logger.info(f"åŠ¨æ€ {dynamic_id} å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶ {total_time.total_seconds():.1f}ç§’")
            
            self.stats['processed_dynamics'] += 1
            return True
            
        except Exception as e:
            self.logger.error(f"å¤„ç†åŠ¨æ€ {dynamic_info.get('id_str', 'unknown')} å¤±è´¥: {e}")
            self.stats['failed_dynamics'] += 1
            return False
    
    async def crawl_user_dynamics(self, uid: int, save_dir: str = "dynamics", 
                                include_comments: bool = True, 
                                start_page: int = 1, max_pages: Optional[int] = None) -> Dict:
        """
        çˆ¬å–ç”¨æˆ·æ‰€æœ‰åŠ¨æ€å’Œè¯„è®º
        
        Args:
            uid: ç”¨æˆ·ID
            save_dir: ä¿å­˜ç›®å½•
            include_comments: æ˜¯å¦åŒ…å«è¯„è®º
            start_page: èµ·å§‹é¡µç 
            max_pages: æœ€å¤§çˆ¬å–é¡µæ•°
            
        Returns:
            Dict: çˆ¬å–ç»Ÿè®¡ä¿¡æ¯
        """
        self.stats['start_time'] = datetime.now()
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_info = await self.get_user_info(uid)
        if not user_info:
            self.logger.error(f"æ— æ³•è·å–ç”¨æˆ· {uid} çš„ä¿¡æ¯")
            return self.stats
        
        username = user_info.get('name', f'UID_{uid}')
        self.logger.info(f"å¼€å§‹çˆ¬å–ç”¨æˆ· {username} (UID: {uid}) çš„åŠ¨æ€")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        save_path = Path(save_dir) / f"{username}_{uid}" / "dynamics"
        save_path.mkdir(parents=True, exist_ok=True)
        
        # é€é¡µè·å–å’Œå¤„ç†åŠ¨æ€
        user_obj = user.User(uid, credential=self.credential)
        offset = ""
        page = 1
        pages_crawled = 0
        total_dynamics_processed = 0
        
        self.logger.info(f"å¼€å§‹é€é¡µè·å–å’Œå¤„ç†åŠ¨æ€...")
        
        while True:
            if max_pages is not None and pages_crawled >= max_pages:
                self.logger.info(f"å·²è¾¾åˆ°æœ€å¤§çˆ¬å–é¡µæ•°é™åˆ¶ ({max_pages}é¡µ)ï¼Œåœæ­¢è·å–ã€‚")
                break

            try:
                # è·å–å½“å‰é¡µåŠ¨æ€
                dynamics_data = await self._get_dynamics_page(user_obj, offset)
                
                if not dynamics_data or not dynamics_data.get('items'):
                    break
                
                if page >= start_page:
                    dynamics_list = dynamics_data['items']
                    pages_crawled += 1
                    
                    self.logger.info(f"è·å–ç¬¬ {page} é¡µï¼Œ{len(dynamics_list)} æ¡åŠ¨æ€ï¼Œå¼€å§‹å¤„ç†...")
                    
                    # ç«‹å³å¤„ç†è¿™é¡µçš„åŠ¨æ€
                    tasks = []
                    for dynamic_info in dynamics_list:
                        task = self.process_single_dynamic(dynamic_info, save_path, include_comments)
                        tasks.append(task)
                    
                    # å¹¶å‘æ‰§è¡Œå½“å‰é¡µçš„ä»»åŠ¡
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    
                    # ç»Ÿè®¡å½“å‰é¡µç»“æœ
                    page_success_count = sum(1 for result in results if result is True)
                    total_dynamics_processed += len(dynamics_list)
                    
                    self.logger.info(f"ç¬¬ {page} é¡µå¤„ç†å®Œæˆ: {page_success_count}/{len(dynamics_list)} æˆåŠŸ, "
                                   f"ç´¯è®¡å¤„ç† {total_dynamics_processed} æ¡åŠ¨æ€")
                    
                else:
                    self.logger.info(f"è·³è¿‡ç¬¬ {page} é¡µ (èµ·å§‹é¡µ: {start_page})")

                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                if not dynamics_data.get('offset') or len(dynamics_data['items']) == 0:
                    break
                
                offset = dynamics_data['offset']
                page += 1
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(0.1)
                
            except Exception as e:
                self.logger.error(f"å¤„ç†ç¬¬ {page} é¡µåŠ¨æ€å¤±è´¥: {e}")
                break
        
        if total_dynamics_processed == 0:
            self.logger.warning("æœªæ‰¾åˆ°ä»»ä½•åŠ¨æ€")
            return self.stats
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.stats['total_dynamics'] = total_dynamics_processed
        
        # ä¿å­˜çˆ¬å–å…ƒä¿¡æ¯
        # å¤„ç† stats ä¸­çš„ datetime å¯¹è±¡ï¼Œé¿å… JSON åºåˆ—åŒ–é”™è¯¯
        stats_copy = self.stats.copy()
        if 'start_time' in stats_copy and isinstance(stats_copy['start_time'], datetime):
            stats_copy['start_time'] = stats_copy['start_time'].isoformat()
            
        metadata = {
            'user_info': user_info,
            'crawl_stats': stats_copy,
            'crawl_time': datetime.now().isoformat(),
            'total_dynamics': total_dynamics_processed,
            'processed_dynamics': self.stats['processed_dynamics'],
            'include_comments': include_comments
        }
        
        metadata_path = save_path.parent / "metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # è¾“å‡ºç»Ÿè®¡ç»“æœ
        duration = datetime.now() - self.stats['start_time']
        self.logger.info(f"çˆ¬å–å®Œæˆï¼")
        self.logger.info(f"æ€»åŠ¨æ€æ•°: {total_dynamics_processed}")
        self.logger.info(f"æˆåŠŸå¤„ç†: {self.stats['processed_dynamics']}")
        self.logger.info(f"å¤±è´¥æ•°: {self.stats['failed_dynamics']}")
        if include_comments:
            self.logger.info(f"æ€»è¯„è®ºæ•°: {self.stats['total_comments']}")
        self.logger.info(f"è€—æ—¶: {duration}")
        
        return self.stats


class BilibiliDynamicManager:
    """BilibiliåŠ¨æ€ç®¡ç†å™¨ - æ•´åˆåŠ¨æ€ç›¸å…³åŠŸèƒ½"""
    
    def __init__(self, download_dir: str = "downloads", max_concurrent: int = 1, 
                 credential: Optional[Credential] = None, max_comments: int = -1,
                 base_wait_time: float = 0.1, full_sub_comments: bool = False):
        """
        åˆå§‹åŒ–åŠ¨æ€ç®¡ç†å™¨
        
        Args:
            download_dir: ä¸‹è½½ç›®å½•
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            credential: Bç«™ç™»å½•å‡­æ®
            max_comments: æ¯ä¸ªåŠ¨æ€æœ€å¤§è¯„è®ºæ•°é™åˆ¶ (-1 è¡¨ç¤ºæ— é™åˆ¶)
            base_wait_time: è¯·æ±‚ä¹‹é—´çš„åŸºæœ¬ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤0.1ç§’ï¼‰
            full_sub_comments: æ˜¯å¦è·å–å®Œæ•´æ¥¼ä¸­æ¥¼è¯„è®º (False=ä»…ä½¿ç”¨å†…åµŒæ¥¼ä¸­æ¥¼, True=å•ç‹¬è·å–å®Œæ•´æ¥¼ä¸­æ¥¼)
        """
        self.download_dir = Path(download_dir)
        self.credential = credential
        
        # åˆ›å»ºåŠ¨æ€çˆ¬å–å™¨
        self.dynamics_crawler = DynamicsCrawler(
            credential=credential, 
            max_concurrent=max_concurrent,
            max_comments_per_dynamic=max_comments,
            base_wait_time=base_wait_time,
            full_sub_comments=full_sub_comments
        )
        # ä½¿ç”¨ç»Ÿä¸€çš„æ—¥å¿—é…ç½®
        self.logger = get_logger('DynamicManager')
    
    async def get_user_info(self, uid: int) -> Dict:
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        return await self.dynamics_crawler.get_user_info(uid)
    
    async def list_user_dynamics(self, uid: int, limit: Optional[int] = None) -> None:
        """
        åˆ—å‡ºç”¨æˆ·æœ€è¿‘çš„åŠ¨æ€
        
        Args:
            uid: ç”¨æˆ·ID
            limit: æ˜¾ç¤ºåŠ¨æ€æ•°é‡é™åˆ¶ (é»˜è®¤: 100)
        """
        # è®¾ç½®é»˜è®¤é™åˆ¶ä¸º100æ¡
        if limit is None:
            limit = 100
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_info = await self.get_user_info(uid)
        if not user_info:
            print(f"âŒ æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·ID: {uid}")
            return
        
        username = user_info.get('name', 'Unknown')
        print(f"\nç”¨æˆ·ï¼š{username} (UID: {uid})")
        
        # è·å–åŠ¨æ€åˆ—è¡¨ï¼ˆæ”¯æŒå¤šé¡µè·å–ï¼‰
        try:
            user_obj = user.User(uid, credential=self.credential)
            all_dynamics = []
            offset = ""
            page = 1
            
            print(f"ğŸ“¦ æ­£åœ¨è·å–æœ€è¿‘ {limit} æ¡åŠ¨æ€...")
            
            while len(all_dynamics) < limit:
                dynamics_data = await self.dynamics_crawler._get_dynamics_page(user_obj, offset)
                
                if not dynamics_data or not dynamics_data.get('items'):
                    break
                
                dynamics_list = dynamics_data['items']
                all_dynamics.extend(dynamics_list)
                
                # å¦‚æœæ˜¯ç¬¬ä¸€é¡µä¸”å·²æ»¡è¶³éœ€æ±‚ï¼Œç›´æ¥è·³å‡º
                if page == 1 and len(dynamics_list) >= limit:
                    break
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                if not dynamics_data.get('offset') or len(dynamics_list) == 0:
                    break
                
                # æ˜¾ç¤ºè¿›åº¦ï¼ˆä»…åœ¨éœ€è¦å¤šé¡µæ—¶ï¼‰
                if page == 1 and len(dynamics_list) < limit:
                    print(f"ğŸ“„ ç¬¬1é¡µå·²è·å– {len(dynamics_list)} æ¡ï¼Œç»§ç»­è·å–æ›´å¤š...")
                elif page > 1:
                    print(f"ğŸ“„ ç¬¬{page}é¡µå·²è·å–ï¼Œç´¯è®¡ {len(all_dynamics)} æ¡...")
                
                offset = dynamics_data['offset']
                page += 1
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(0.1)
                
                # å®‰å…¨é™åˆ¶ï¼šæœ€å¤šè·å–10é¡µ
                if page > 10:
                    self.logger.warning(f"å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶(10é¡µ)ï¼Œåœæ­¢è·å–")
                    break
            
            # æˆªå–æ‰€éœ€æ•°é‡
            dynamics_list = all_dynamics[:limit]
            
            if not dynamics_list:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•åŠ¨æ€")
                return
            
            print(f"âœ… æˆåŠŸè·å– {len(dynamics_list)} æ¡åŠ¨æ€\n")
            
            for i, dynamic_info in enumerate(dynamics_list, 1):
                dynamic_type = dynamic_info.get('type', 'UNKNOWN')
                dynamic_id = dynamic_info['id_str']
                
                # è§£æåŠ¨æ€å†…å®¹
                modules = dynamic_info.get('modules', {})
                desc_text = ""
                
                # å°è¯•è·å–åŠ¨æ€æè¿°æ–‡æœ¬
                if modules.get('module_dynamic', {}).get('desc'):
                    desc_text = modules['module_dynamic']['desc'].get('text', '')[:100]
                elif modules.get('module_dynamic', {}).get('major', {}).get('opus'):
                    # å›¾æ–‡åŠ¨æ€
                    opus = modules['module_dynamic']['major']['opus']
                    if opus.get('summary', {}).get('text'):
                        desc_text = opus['summary']['text'][:100]
                    elif opus.get('title'):
                        desc_text = opus['title']
                
                # å‘å¸ƒæ—¶é—´
                pub_time = datetime.fromtimestamp(dynamic_info.get('modules', {}).get('module_author', {}).get('pub_ts', 0))
                pub_time_str = pub_time.strftime('%Y-%m-%d %H:%M')
                
                print(f"{i:3d}. [{dynamic_type}] {dynamic_id}")
                print(f"     ğŸ“… {pub_time_str}")
                if desc_text:
                    print(f"     ğŸ“ {desc_text}{'...' if len(desc_text) >= 100 else ''}")
                print()
                
        except Exception as e:
            self.logger.error(f"è·å–ç”¨æˆ·åŠ¨æ€å¤±è´¥: {e}")
            print(f"âŒ è·å–ç”¨æˆ·åŠ¨æ€å¤±è´¥: {e}")
    
    async def download_user_dynamics(self, uid: int, include_comments: bool = True, 
                                   max_comments: int = -1, start_page: int = 0, total_pages: int = 0) -> None:
        """
        ä¸‹è½½ç”¨æˆ·æ‰€æœ‰åŠ¨æ€å’Œè¯„è®º
        
        Args:
            uid: ç”¨æˆ·ID
            include_comments: æ˜¯å¦åŒ…å«è¯„è®º
            max_comments: æ¯ä¸ªåŠ¨æ€æœ€å¤§è¯„è®ºæ•°é™åˆ¶ (-1 è¡¨ç¤ºæ— é™åˆ¶)
        """
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_info = await self.get_user_info(uid)
        if not user_info:
            print(f"âŒ æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·ID: {uid}")
            return
        
        username = user_info.get('name', 'Unknown')
        print(f"\nå¼€å§‹ä¸‹è½½ç”¨æˆ· {username} (UID: {uid}) çš„åŠ¨æ€{'å’Œè¯„è®º' if include_comments else ''}")
        
        # è®¾ç½®åŠ¨æ€çˆ¬å–å™¨å‚æ•°
        self.dynamics_crawler.max_comments_per_dynamic = max_comments
        
        try:
            # æ‰§è¡Œçˆ¬å–
            stats = await self.dynamics_crawler.crawl_user_dynamics(
                uid=uid,
                save_dir=str(self.download_dir),
                include_comments=include_comments,
                start_page=start_page,
                max_pages=total_pages if total_pages > 0 else None
            )
            
            # æ˜¾ç¤ºç»“æœç»Ÿè®¡
            print(f"\nğŸ“Š åŠ¨æ€ä¸‹è½½å®Œæˆï¼")
            print(f"æ€»åŠ¨æ€æ•°: {stats['total_dynamics']}")
            print(f"æˆåŠŸå¤„ç†: {stats['processed_dynamics']}")
            print(f"å¤±è´¥æ•°: {stats['failed_dynamics']}")
            if include_comments:
                print(f"æ€»è¯„è®ºæ•°: {stats['total_comments']}")
            
        except Exception as e:
            self.logger.error(f"ä¸‹è½½ç”¨æˆ·åŠ¨æ€å¤±è´¥: {e}")
            print(f"âŒ ä¸‹è½½ç”¨æˆ·åŠ¨æ€å¤±è´¥: {e}")
    
    @api_retry_decorator()
    async def _get_dynamic_info(self, dynamic_obj: Dynamic) -> Dict:
        """è·å–å•ä¸ªåŠ¨æ€çš„è¯¦ç»†ä¿¡æ¯"""
        return await dynamic_obj.get_info()

    async def download_single_dynamic(self, dynamic_id: int, include_comments: bool = True) -> None:
        """
        ä¸‹è½½å•ä¸ªåŠ¨æ€å’Œè¯„è®º
        
        Args:
            dynamic_id: åŠ¨æ€ID
            include_comments: æ˜¯å¦åŒ…å«è¯„è®º
        """
        try:
            # åˆ›å»ºåŠ¨æ€å¯¹è±¡
            dynamic_obj = Dynamic(dynamic_id, credential=self.credential)
            
            # è·å–åŠ¨æ€è¯¦ç»†ä¿¡æ¯
            dynamic_info = await self._get_dynamic_info(dynamic_obj)
            
            if not dynamic_info:
                print(f"âŒ æ— æ³•è·å–åŠ¨æ€ {dynamic_id} çš„ä¿¡æ¯")
                return
            
            # åˆ›å»ºä¿å­˜ç›®å½•
            save_path = self.download_dir / "single_dynamics"
            save_path.mkdir(parents=True, exist_ok=True)
            
            print(f"\nå¼€å§‹ä¸‹è½½åŠ¨æ€ {dynamic_id}{'å’Œè¯„è®º' if include_comments else ''}")
            
            # å¤„ç†åŠ¨æ€
            success = await self.dynamics_crawler.process_single_dynamic(
                dynamic_info['item'], 
                save_path, 
                include_comments
            )
            
            if success:
                print(f"âœ… åŠ¨æ€ä¸‹è½½å®Œæˆ")
            else:
                print(f"âŒ åŠ¨æ€ä¸‹è½½å¤±è´¥")
                
        except Exception as e:
            self.logger.error(f"ä¸‹è½½å•ä¸ªåŠ¨æ€å¤±è´¥: {e}")
            print(f"âŒ ä¸‹è½½å•ä¸ªåŠ¨æ€å¤±è´¥: {e}")